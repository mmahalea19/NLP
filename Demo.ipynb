{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Demo.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "pycharm-ebd2ea66",
   "language": "python",
   "display_name": "PyCharm (NLP)"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/mmahalea19/NLP/blob/master/Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "LUXH7l86QVFR",
    "colab_type": "code",
    "outputId": "0e38b2b1-7e8b-4e46-bc6a-9f397587b81f",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "NOTE!!! Keep the same folder structure W"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-1f500f859c75>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    NOTE!!! Keep the same folder structure W\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ],
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-1f500f859c75>, line 1)",
     "output_type": "error"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "BpG_73RgQc9N",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "Hi , aksl"
   ],
   "execution_count": 2,
   "outputs": [
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-ba922382b6c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mHi\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0maksl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Hi' is not defined"
     ],
     "ename": "NameError",
     "evalue": "name 'Hi' is not defined",
     "output_type": "error"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9MfwkRWy-Yz1",
    "colab_type": "text"
   },
   "source": [
    "Task 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "The final result for the classifiers 1|2|3=0\n",
      "The final result for the classifiers 1|3|2=0\n",
      "The final result for the classifiers 2|1|3=1\n",
      "The final result for the classifiers 2|3|1=1\n",
      "The final result for the classifiers 3|1|2=0\n",
      "The final result for the classifiers 3|2|1=1\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from itertools import permutations \n",
    "from random import randint\n",
    "class mock_class:\n",
    "    def predict(self,s):\n",
    "        return randint(0,1)\n",
    "        \n",
    "def majority_voting(classifiers,classifier_labels,sample):\n",
    "    results=[]\n",
    "    classifier_order=range(0,len(classifiers)-1);\n",
    "    k=3\n",
    "    combinations=permutations(classifier_order,k)\n",
    "    for index,i in enumerate(list(combinations)):\n",
    "        majority_vote=classifiers[i[0]].predict(sample)+classifiers[i[1]].predict(sample)+classifiers[i[2]].predict(sample);\n",
    "        final_result=round(majority_vote/k);\n",
    "        results.append(final_result)\n",
    "        print(\"The final result for the classifiers {}|{}|{}={}\".format(classifier_labels[i[0]],classifier_labels[i[1]],classifier_labels[i[2]],final_result))\n",
    "fake1=mock_class()\n",
    "fake2=mock_class()\n",
    "fake3=mock_class()\n",
    "fake4=mock_class()\n",
    "classSet=[fake1,fake2,fake3,fake4]\n",
    "classLabels=range(1,4)\n",
    "x=3\n",
    "majority_voting(classSet,classLabels,x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ssF2WdoPWKA4",
    "colab_type": "text"
   },
   "source": [
    "NOTE!!! Keep the same folder structure as described below, when downloading the Enron dataset:\n",
    "\n",
    "Enron_PRE\n",
    "\n",
    "Enron_RAW"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Yzi8AZ_MWWKX",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6FV8xEnwC4fA",
    "colab_type": "text"
   },
   "source": [
    "Task 4-remove stopwords and others\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zIcAZLmmC8c4",
    "colab_type": "code",
    "outputId": "7457a048-2513-4629-dbe0-3b5f42d6f97f",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "import nltk\n",
    "import re\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize ,RegexpTokenizer\n",
    "import string as string\n",
    "def removeWords(phrases,options):\n",
    "  print(\"Initial\")\n",
    "  print(phrases)\n",
    "  if(\"link\" in options):\n",
    "    phrases=[re.sub(r'''(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\".,<>?«»“”‘’]))''', \" \", phrase) for phrase in phrases]\n",
    "    print(\"After link\")\n",
    "    print(phrases)\n",
    "  if \"symbol\" in options:\n",
    "    whitelist = string.ascii_letters + string.digits + ' '\n",
    "    symbolRemoved=[]\n",
    "    for phrase in phrases:\n",
    "      phrase1=''.join(list(map(lambda cha: cha if cha  in whitelist else ' ',phrase)))\n",
    "      symbolRemoved.append(phrase1)\n",
    "    print(\"After symbol removal\")\n",
    "\n",
    "    phrases=symbolRemoved\n",
    "    print(phrases)\n",
    "\n",
    "\n",
    "  tokenized=[word_tokenize(phrase) for phrase in phrases] #split in individual words\n",
    "  print(tokenized)\n",
    "  if \"stopword\" in options:\n",
    "    stop_words = set(stopwords.words('english')) #get set of stopwords\n",
    "    filtered=list(map(lambda phrase:[w for w in phrase if w not in stop_words],tokenized)) # remove words that appear in the stopwords set\n",
    "    print(\"After stopword removal\")\n",
    "\n",
    "    tokenized=filtered\n",
    "    #phrases=''.join(filtered)\n",
    "    phrases=[' '.join(x) for x in filtered]\n",
    "    print(phrases)\n",
    "    print(\"Done\")\n",
    "\n",
    "removeWords([\"This is-a really nice day to. ? swim in the ocean\",\"Hello  @my friends https://mdshasdasdhas carte\"],[\"stopword\",\"symbol\",\"link\"])"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/mihai/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to /home/mihai/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "Initial\n",
      "['This is-a really nice day to. ? swim in the ocean', 'Hello  @my friends https://mdshasdasdhas carte']\n",
      "After link\n",
      "['This is-a really nice day to. ? swim in the ocean', 'Hello  @my friends   carte']\n",
      "After symbol removal\n",
      "['This is a really nice day to    swim in the ocean', 'Hello   my friends   carte']\n",
      "[['This', 'is', 'a', 'really', 'nice', 'day', 'to', 'swim', 'in', 'the', 'ocean'], ['Hello', 'my', 'friends', 'carte']]\n",
      "After stopword removal\n",
      "['This really nice day swim ocean', 'Hello friends carte']\n",
      "Done\n"
     ],
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "re2S7W3CTGKv",
    "colab_type": "code",
    "colab": {},
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    ""
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}